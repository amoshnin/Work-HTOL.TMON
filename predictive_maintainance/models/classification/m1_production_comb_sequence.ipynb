{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SequenceAlertPredictor:\n",
    "    def __init__(self, model_type='xgboost', sequence_length=24):  # 24 hours of data\n",
    "        \"\"\"\n",
    "        Initializes the SequenceAlertPredictor with the specified model type and sequence length.\n",
    "\n",
    "        Args:\n",
    "            model_type (str): Type of model to use ('xgboost' or 'randomforest')\n",
    "            sequence_length (int): Number of time points to use for prediction\n",
    "        \"\"\"\n",
    "        self.model_type = model_type\n",
    "        self.sequence_length = sequence_length\n",
    "        self.models = {}\n",
    "        self.scalers = {}\n",
    "        self.alert_types = ['LOW', 'MEDIUM', 'HIGH']\n",
    "        self.base_features = ['ChlPrs', 'rolling_mean', 'rolling_std']\n",
    "        self.features = []\n",
    "        for feature in self.base_features:\n",
    "            self.features.extend([f'{feature}_t{i}' for i in range(sequence_length)])\n",
    "        self.features.extend([f'time_since_{at}' for at in self.alert_types])\n",
    "\n",
    "    def load_and_preprocess_data(self, folder):\n",
    "        \"\"\"\n",
    "        Loads and preprocesses data from CSV files in the specified folder.\n",
    "        \"\"\"\n",
    "        dfs = []\n",
    "        for i in range(9, 16):\n",
    "            file_name = f\"HTOL-{i:02d}_alerts.csv\"\n",
    "            df = pd.read_csv(os.path.join(folder, file_name))\n",
    "            df['machine_id'] = f'HTOL-{i:02d}'\n",
    "            dfs.append(df)\n",
    "\n",
    "        combined_df = pd.concat(dfs, ignore_index=True)\n",
    "        combined_df['Time'] = pd.to_datetime(combined_df['Time'])\n",
    "        combined_df = combined_df.sort_values(['machine_id', 'Time'])\n",
    "\n",
    "        return combined_df\n",
    "\n",
    "    def create_sequences(self, df):\n",
    "        \"\"\"\n",
    "        Creates sequences of data points for each machine.\n",
    "        \"\"\"\n",
    "        sequences = []\n",
    "        labels = []\n",
    "\n",
    "        for machine_id in df['machine_id'].unique():\n",
    "            machine_data = df[df['machine_id'] == machine_id].copy()\n",
    "\n",
    "            for i in range(len(machine_data) - self.sequence_length):\n",
    "                sequence = machine_data.iloc[i:i + self.sequence_length]\n",
    "                target_row = machine_data.iloc[i + self.sequence_length]\n",
    "\n",
    "                sequence_features = {}\n",
    "\n",
    "                # Add sequential features\n",
    "                for feature in self.base_features:\n",
    "                    for j in range(self.sequence_length):\n",
    "                        sequence_features[f'{feature}_t{j}'] = sequence.iloc[j][feature]\n",
    "\n",
    "                # Add time since last alert features\n",
    "                for alert_type in self.alert_types:\n",
    "                    sequence_features[f'time_since_{alert_type}'] = target_row[f'time_since_{alert_type}']\n",
    "\n",
    "                sequences.append(sequence_features)\n",
    "                labels.append(1 if target_row['ALERT'] == self.current_alert_type else 0)\n",
    "\n",
    "        return pd.DataFrame(sequences), np.array(labels)\n",
    "\n",
    "    def engineer_features(self, df):\n",
    "        \"\"\"\n",
    "        Engineers features from the preprocessed data.\n",
    "        \"\"\"\n",
    "        df['rolling_mean'] = df.groupby('machine_id')['ChlPrs'].rolling(\n",
    "            window=24, min_periods=1).mean().reset_index(0, drop=True)\n",
    "        df['rolling_std'] = df.groupby('machine_id')['ChlPrs'].rolling(\n",
    "            window=24, min_periods=1).std().reset_index(0, drop=True)\n",
    "\n",
    "        for alert_type in self.alert_types:\n",
    "            df[f'time_since_{alert_type}'] = df.groupby('machine_id').apply(\n",
    "                lambda x: x['Time'] - x[x['ALERT'] == alert_type]['Time'].shift(1)\n",
    "            ).reset_index(level=0, drop=True)\n",
    "            df[f'time_since_{alert_type}'] = df[f'time_since_{alert_type}'].dt.total_seconds() / 3600\n",
    "\n",
    "        return df\n",
    "\n",
    "    def train_and_evaluate_classifier(self, X, y, test_size=0.2):\n",
    "        \"\"\"\n",
    "        Trains and evaluates the classification model.\n",
    "        \"\"\"\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        if self.model_type == 'xgboost':\n",
    "            model = XGBClassifier(\n",
    "                n_estimators=100,\n",
    "                learning_rate=0.1,\n",
    "                max_depth=6,\n",
    "                scale_pos_weight=len(y_train[y_train == 0]) / len(y_train[y_train == 1]),\n",
    "                random_state=42\n",
    "            )\n",
    "        else:  # randomforest\n",
    "            model = RandomForestClassifier(\n",
    "                n_estimators=100,\n",
    "                class_weight='balanced',\n",
    "                random_state=42\n",
    "            )\n",
    "\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "        return model, scaler\n",
    "\n",
    "    def train(self, folder):\n",
    "        \"\"\"\n",
    "        Trains models for each alert type.\n",
    "        \"\"\"\n",
    "        df = self.load_and_preprocess_data(folder)\n",
    "        df = self.engineer_features(df)\n",
    "\n",
    "        for alert_type in self.alert_types:\n",
    "            print(f\"\\nTraining model for {alert_type} alerts:\")\n",
    "            self.current_alert_type = alert_type\n",
    "            X, y = self.create_sequences(df)\n",
    "            model, scaler = self.train_and_evaluate_classifier(X, y)\n",
    "            self.models[alert_type] = model\n",
    "            self.scalers[alert_type] = scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ProductionSequencePredictor:\n",
    "    def __init__(self, model_types=['xgboost', 'randomforest'], sequence_length=24):\n",
    "        \"\"\"\n",
    "        Initializes the ProductionSequencePredictor with multiple model types.\n",
    "        \"\"\"\n",
    "        self.model_types = model_types\n",
    "        self.sequence_length = sequence_length\n",
    "        self.models = {model_type: {} for model_type in model_types}\n",
    "        self.scalers = {model_type: {} for model_type in model_types}\n",
    "        self.alert_types = ['LOW', 'MEDIUM', 'HIGH']\n",
    "        self.base_features = ['ChlPrs', 'rolling_mean', 'rolling_std']\n",
    "        self.features = []\n",
    "        for feature in self.base_features:\n",
    "            self.features.extend([f'{feature}_t{i}' for i in range(sequence_length)])\n",
    "        self.features.extend([f'time_since_{at}' for at in self.alert_types])\n",
    "\n",
    "    def prepare_sequence(self, df):\n",
    "        \"\"\"\n",
    "        Prepares a sequence of data points for prediction.\n",
    "        \"\"\"\n",
    "        if len(df) < self.sequence_length:\n",
    "            raise ValueError(f\"Input data must contain at least {self.sequence_length} points\")\n",
    "\n",
    "        sequence = df.iloc[-self.sequence_length:]\n",
    "        sequence_features = {}\n",
    "\n",
    "        for feature in self.base_features:\n",
    "            for j in range(self.sequence_length):\n",
    "                sequence_features[f'{feature}_t{j}'] = sequence.iloc[j][feature]\n",
    "\n",
    "        for alert_type in self.alert_types:\n",
    "            sequence_features[f'time_since_{alert_type}'] = df.iloc[-1][f'time_since_{alert_type}']\n",
    "\n",
    "        return pd.DataFrame([sequence_features])\n",
    "\n",
    "    def save_models(self, output_dir):\n",
    "        \"\"\"\n",
    "        Saves trained models and metadata to disk.\n",
    "        \"\"\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        metadata = {\n",
    "            'model_types': self.model_types,\n",
    "            'alert_types': self.alert_types,\n",
    "            'sequence_length': self.sequence_length,\n",
    "            'features': self.features,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "\n",
    "        with open(os.path.join(output_dir, 'metadata.json'), 'w') as f:\n",
    "            json.dump(metadata, f, indent=4)\n",
    "\n",
    "        for model_type in self.model_types:\n",
    "            model_dir = os.path.join(output_dir, model_type)\n",
    "            os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "            for alert_type in self.alert_types:\n",
    "                with open(os.path.join(model_dir, f'{alert_type}_model.pkl'), 'wb') as f:\n",
    "                    pickle.dump(self.models[model_type][alert_type], f)\n",
    "                with open(os.path.join(model_dir, f'{alert_type}_scaler.pkl'), 'wb') as f:\n",
    "                    pickle.dump(self.scalers[model_type][alert_type], f)\n",
    "\n",
    "    @classmethod\n",
    "    def load_models(cls, model_dir):\n",
    "        \"\"\"\n",
    "        Loads trained models from disk.\n",
    "        \"\"\"\n",
    "        with open(os.path.join(model_dir, 'metadata.json'), 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "\n",
    "        predictor = cls(\n",
    "            model_types=metadata['model_types'],\n",
    "            sequence_length=metadata['sequence_length']\n",
    "        )\n",
    "\n",
    "        for model_type in predictor.model_types:\n",
    "            model_type_dir = os.path.join(model_dir, model_type)\n",
    "\n",
    "            for alert_type in predictor.alert_types:\n",
    "                with open(os.path.join(model_type_dir, f'{alert_type}_model.pkl'), 'rb') as f:\n",
    "                    predictor.models[model_type][alert_type] = pickle.load(f)\n",
    "                with open(os.path.join(model_type_dir, f'{alert_type}_scaler.pkl'), 'rb') as f:\n",
    "                    predictor.scalers[model_type][alert_type] = pickle.load(f)\n",
    "\n",
    "        return predictor\n",
    "\n",
    "    def predict(self, df, threshold=0.7):\n",
    "        \"\"\"\n",
    "        Makes predictions using the ensemble of models.\n",
    "        \"\"\"\n",
    "        sequence = self.prepare_sequence(df)\n",
    "        results = {}\n",
    "\n",
    "        for alert_type in self.alert_types:\n",
    "            model_predictions = []\n",
    "            model_probabilities = []\n",
    "\n",
    "            for model_type in self.model_types:\n",
    "                X_scaled = self.scalers[model_type][alert_type].transform(sequence)\n",
    "                probabilities = self.models[model_type][alert_type].predict_proba(X_scaled)[:, 1]\n",
    "                predictions = (probabilities >= threshold).astype(int)\n",
    "\n",
    "                model_predictions.append(predictions)\n",
    "                model_probabilities.append(probabilities)\n",
    "\n",
    "            # Unanimous ensemble prediction\n",
    "            final_predictions = np.all(model_predictions, axis=0)\n",
    "            avg_probabilities = np.mean(model_probabilities, axis=0)\n",
    "\n",
    "            results[alert_type] = {\n",
    "                'prediction': final_predictions[0],\n",
    "                'probability': avg_probabilities[0],\n",
    "                'model_probabilities': {\n",
    "                    model_type: probs[0]\n",
    "                    for model_type, probs in zip(self.model_types, model_probabilities)\n",
    "                }\n",
    "            }\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_production_models(data_folder, output_dir, sequence_length=24):\n",
    "    \"\"\"\n",
    "    Trains and saves production models.\n",
    "    \"\"\"\n",
    "    xgb_predictor = SequenceAlertPredictor(model_type='xgboost', sequence_length=sequence_length)\n",
    "    rf_predictor = SequenceAlertPredictor(model_type='randomforest', sequence_length=sequence_length)\n",
    "\n",
    "    xgb_predictor.train(data_folder)\n",
    "    rf_predictor.train(data_folder)\n",
    "\n",
    "    prod_predictor = ProductionSequencePredictor(['xgboost', 'randomforest'], sequence_length)\n",
    "\n",
    "    for alert_type in prod_predictor.alert_types:\n",
    "        prod_predictor.models['xgboost'][alert_type] = xgb_predictor.models[alert_type]\n",
    "        prod_predictor.scalers['xgboost'][alert_type] = xgb_predictor.scalers[alert_type]\n",
    "        prod_predictor.models['randomforest'][alert_type] = rf_predictor.models[alert_type]\n",
    "        prod_predictor.scalers['randomforest'][alert_type] = rf_predictor.scalers[alert_type]\n",
    "\n",
    "    prod_predictor.save_models(output_dir)\n",
    "    return prod_predictor\n",
    "\n",
    "def visualize_predictions(predictor, df, alert_type, window_size=168):  # 1 week\n",
    "    \"\"\"\n",
    "    Visualizes predictions vs actual alerts.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    actual_alerts = []\n",
    "    timestamps = []\n",
    "\n",
    "    for i in range(predictor.sequence_length, len(df)):\n",
    "        sequence_df = df.iloc[max(0, i-window_size):i]\n",
    "        if len(sequence_df) >= predictor.sequence_length:\n",
    "            pred = predictor.predict(sequence_df)\n",
    "            predictions.append(pred[alert_type]['probability'])\n",
    "            actual_alerts.append(1 if df.iloc[i]['ALERT'] == alert_type else 0)\n",
    "            timestamps.append(df.iloc[i]['Time'])\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.plot(timestamps, predictions, label='Prediction Probability', color='blue', alpha=0.6)\n",
    "    plt.scatter([t for t, a in zip(timestamps, actual_alerts) if a == 1],\n",
    "                [1 for a in actual_alerts if a == 1],\n",
    "                color='red', label='Actual Alerts', marker='x', s=100)\n",
    "    plt.axhline(y=0.7, color='r', linestyle='--', alpha=0.3, label='Threshold (0.7)')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Alert Probability')\n",
    "    plt.title(f'Predicted vs Actual {alert_type} Alerts')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_production_models(data_folder, output_dir, sequence_length=24):\n",
    "    \"\"\"\n",
    "    Trains and saves production models.\n",
    "    \"\"\"\n",
    "    xgb_predictor = SequenceAlertPredictor(model_type='xgboost', sequence_length=sequence_length)\n",
    "    rf_predictor = SequenceAlertPredictor(model_type='randomforest', sequence_length=sequence_length)\n",
    "\n",
    "    xgb_predictor.train(data_folder)\n",
    "    rf_predictor.train(data_folder)\n",
    "\n",
    "    prod_predictor = ProductionSequencePredictor(['xgboost', 'randomforest'], sequence_length)\n",
    "\n",
    "    for alert_type in prod_predictor.alert_types:\n",
    "        prod_predictor.models['xgboost'][alert_type] = xgb_predictor.models[alert_type]\n",
    "        prod_predictor.scalers['xgboost'][alert_type] = xgb_predictor.scalers[alert_type]\n",
    "        prod_predictor.models['randomforest'][alert_type] = rf_predictor.models[alert_type]\n",
    "        prod_predictor.scalers['randomforest'][alert_type] = rf_predictor.scalers[alert_type]\n",
    "\n",
    "    prod_predictor.save_models(output_dir)\n",
    "    return prod_predictor\n",
    "\n",
    "def visualize_predictions(predictor, df, alert_type, window_size=168):  # 1 week\n",
    "    \"\"\"\n",
    "    Visualizes predictions vs actual alerts.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    actual_alerts = []\n",
    "    timestamps = []\n",
    "\n",
    "    for i in range(predictor.sequence_length, len(df)):\n",
    "        sequence_df = df.iloc[max(0, i-window_size):i]\n",
    "        if len(sequence_df) >= predictor.sequence_length:\n",
    "            pred = predictor.predict(sequence_df)\n",
    "            predictions.append(pred[alert_type]['probability'])\n",
    "            actual_alerts.append(1 if df.iloc[i]['ALERT'] == alert_type else 0)\n",
    "            timestamps.append(df.iloc[i]['Time'])\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.plot(timestamps, predictions, label='Prediction Probability', color='blue', alpha=0.6)\n",
    "    plt.scatter([t for t, a in zip(timestamps, actual_alerts) if a == 1],\n",
    "                [1 for a in actual_alerts if a == 1],\n",
    "                color='red', label='Actual Alerts', marker='x', s=100)\n",
    "    plt.axhline(y=0.7, color='r', linestyle='--', alpha=0.3, label='Threshold (0.7)')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Alert Probability')\n",
    "    plt.title(f'Predicted vs Actual {alert_type} Alerts')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading saved models and making predictions\n",
    "predictor = ProductionSequencePredictor.load_models(\"production_sequence_models\")\n",
    "\n",
    "# Load test data\n",
    "test_df = pd.read_csv(\"path_to_test_data.csv\")\n",
    "test_df['Time'] = pd.to_datetime(test_df['Time'])\n",
    "test_df = test_df.sort_values('Time')\n",
    "\n",
    "# Visualize predictions for each alert type\n",
    "for alert_type in predictor.alert_types:\n",
    "    visualize_predictions(predictor, test_df, alert_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d7/0np89js16x9b596pzk8m108c0000gn/T/ipykernel_43256/3248836662.py:78: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f'time_since_{alert_type}'] = df.groupby('machine_id').apply(\n",
      "/var/folders/d7/0np89js16x9b596pzk8m108c0000gn/T/ipykernel_43256/3248836662.py:78: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f'time_since_{alert_type}'] = df.groupby('machine_id').apply(\n",
      "/var/folders/d7/0np89js16x9b596pzk8m108c0000gn/T/ipykernel_43256/3248836662.py:78: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f'time_since_{alert_type}'] = df.groupby('machine_id').apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model for LOW alerts:\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"production_sequence_models\"\n",
    "data_folder = \"../../../outlier_tolerance=5_grouping_time_window=200_anomaly_threshold=6_start_date=2022-01-01_end_date=2026-01-01\"\n",
    "sequence_length = 24  # 24 hours of data\n",
    "\n",
    "predictor = train_production_models(\n",
    "    data_folder=data_folder,\n",
    "    output_dir=output_dir,\n",
    "    sequence_length=sequence_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading saved models and making predictions\n",
    "predictor = ProductionSequencePredictor.load_models(\"production_sequence_models\")\n",
    "\n",
    "# Load test data\n",
    "test_df = pd.read_csv(\"path_to_test_data.csv\")\n",
    "test_df['Time'] = pd.to_datetime(test_df['Time'])\n",
    "test_df = test_df.sort_values('Time')\n",
    "\n",
    "# Visualize predictions for each alert type\n",
    "for alert_type in predictor.alert_types:\n",
    "    visualize_predictions(predictor, test_df, alert_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
