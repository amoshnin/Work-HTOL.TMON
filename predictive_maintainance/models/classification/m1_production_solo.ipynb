{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Union, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AlertPredictor:\n",
    "    def __init__(self, model_type='xgboost'):\n",
    "        \"\"\"\n",
    "        Initializes the AlertPredictor with the specified model type ('xgboost' or 'randomforest').\n",
    "        \"\"\"\n",
    "        self.model_type = model_type\n",
    "        self.models = {}\n",
    "        self.scalers = {}\n",
    "        self.alert_types = ['LOW', 'MEDIUM', 'HIGH', ] # 'SIGMA']\n",
    "        self.features = ['ChlPrs', 'hour', 'day_of_week', 'month', 'is_weekend',\n",
    "                         'rolling_mean', 'rolling_std'] + [f'time_since_{at}' for at in self.alert_types]\n",
    "\n",
    "    def load_and_preprocess_data(self, folder):\n",
    "        \"\"\"\n",
    "        Loads and preprocesses data from CSV files in the specified folder.\n",
    "        \"\"\"\n",
    "        dfs = []\n",
    "        for i in range(9, 16):\n",
    "            file_name = f\"HTOL-{i:02d}_alerts.csv\"\n",
    "            df = pd.read_csv(os.path.join(folder, file_name))\n",
    "            df['machine_id'] = f'HTOL-{i:02d}'\n",
    "            dfs.append(df)\n",
    "\n",
    "        combined_df = pd.concat(dfs, ignore_index=True)\n",
    "        combined_df['Time'] = pd.to_datetime(combined_df['Time'])\n",
    "        combined_df = combined_df.sort_values(['machine_id', 'Time'])\n",
    "\n",
    "        return combined_df\n",
    "\n",
    "    def engineer_features(self, df):\n",
    "        \"\"\"\n",
    "        Engineers features from the preprocessed data.\n",
    "        \"\"\"\n",
    "        df['hour'] = df['Time'].dt.hour\n",
    "        df['day_of_week'] = df['Time'].dt.dayofweek\n",
    "        df['month'] = df['Time'].dt.month\n",
    "        df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "        # Calculate rolling statistics\n",
    "        df['rolling_mean'] = df.groupby('machine_id')['ChlPrs'].rolling(window=24, min_periods=1).mean().reset_index(0, drop=True)\n",
    "        df['rolling_std'] = df.groupby('machine_id')['ChlPrs'].rolling(window=24, min_periods=1).std().reset_index(0, drop=True)\n",
    "\n",
    "        # Calculate time since last alert for each type\n",
    "        for alert_type in self.alert_types:\n",
    "            df[f'time_since_{alert_type}'] = df.groupby('machine_id').apply(\n",
    "                lambda x: x['Time'] - x[x['ALERT'] == alert_type]['Time'].shift(1)).reset_index(level=0, drop=True)\n",
    "            df[f'time_since_{alert_type}'] = df[f'time_since_{alert_type}'].dt.total_seconds() / 3600  # Convert to hours\n",
    "\n",
    "        return df\n",
    "\n",
    "    def prepare_data_for_classification(self, df, target_alert_type, prediction_window):\n",
    "        \"\"\"\n",
    "        Prepares the data for training the classification model.\n",
    "        \"\"\"\n",
    "        df['target'] = df.groupby('machine_id').apply(\n",
    "            lambda x: (x['ALERT'] == target_alert_type).rolling(window=prediction_window).max().shift(-prediction_window + 1)).reset_index(level=0,\n",
    "                                                                                                                                           drop=True)\n",
    "\n",
    "        X = df[self.features]\n",
    "        y = df['target'].fillna(0)  # Fill NaN with 0 (no alert)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def train_and_evaluate_classifier(self, X, y, test_size=0.2):\n",
    "        \"\"\"\n",
    "        Trains and evaluates the classification model.\n",
    "        \"\"\"\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        if self.model_type == 'xgboost':\n",
    "            # XGBoost configuration for imbalanced classification\n",
    "            model = XGBClassifier(\n",
    "                n_estimators=100,\n",
    "                learning_rate=0.1,\n",
    "                max_depth=6,\n",
    "                min_child_weight=1,\n",
    "                gamma=0,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                scale_pos_weight=len(y_train[y_train == 0]) / len(y_train[y_train == 1]),  # Handle class imbalance\n",
    "                random_state=42,\n",
    "                eval_metric='logloss',\n",
    "                early_stopping_rounds=10,\n",
    "            )\n",
    "            model.fit(X_train_scaled, y_train, eval_set=[(X_test_scaled, y_test)], verbose=0)\n",
    "        elif self.model_type == 'randomforest':\n",
    "            model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid model_type. Choose 'xgboost' or 'randomforest'.\")\n",
    "\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "        return model, scaler\n",
    "\n",
    "    def train(self, folder, prediction_window=7):\n",
    "        \"\"\"\n",
    "        Trains the models for each alert type.\n",
    "        \"\"\"\n",
    "        df = self.load_and_preprocess_data(folder)\n",
    "        df = self.engineer_features(df)\n",
    "\n",
    "        for alert_type in self.alert_types:\n",
    "            print(f\"\\nTraining model for {alert_type} alerts:\")\n",
    "            X, y = self.prepare_data_for_classification(df, alert_type, prediction_window)\n",
    "            model, scaler = self.train_and_evaluate_classifier(X, y)\n",
    "            self.models[alert_type] = model\n",
    "            self.scalers[alert_type] = scaler\n",
    "\n",
    "    def predict(self, new_data):\n",
    "        \"\"\"\n",
    "        Makes predictions on new data.\n",
    "        \"\"\"\n",
    "        predictions = {}\n",
    "        for alert_type in self.alert_types:\n",
    "            X_new = new_data[self.features]\n",
    "            X_new_scaled = self.scalers[alert_type].transform(X_new)\n",
    "            alert_probability = self.models[alert_type].predict_proba(X_new_scaled)[0, 1]\n",
    "            predictions[alert_type] = alert_probability\n",
    "        return predictions\n",
    "\n",
    "    def visualize_alerts(self, df, target_alert_type, prediction_window, probability_threshold=0.7):\n",
    "        \"\"\"\n",
    "        Visualizes actual alerts and high-risk periods.\n",
    "        \"\"\"\n",
    "        X = df[self.features]\n",
    "        X_scaled = self.scalers[target_alert_type].transform(X)\n",
    "\n",
    "        df['alert_probability'] = self.models[target_alert_type].predict_proba(X_scaled)[:, 1]\n",
    "        df['high_risk'] = df['alert_probability'] > probability_threshold\n",
    "\n",
    "        plt.figure(figsize=(20, 15))\n",
    "        machines = df['machine_id'].unique()\n",
    "        n_machines = len(machines)\n",
    "\n",
    "        for i, machine_id in enumerate(machines):\n",
    "            machine_df = df[df['machine_id'] == machine_id]\n",
    "\n",
    "            # Plot actual alerts\n",
    "            alerts = machine_df[machine_df['ALERT'] == target_alert_type]\n",
    "            plt.scatter(alerts['Time'], [i - 0.2] * len(alerts), marker='o', s=100,\n",
    "                        label=f'Actual {target_alert_type} Alert' if i == 0 else \"\")\n",
    "\n",
    "            # Plot high-risk periods\n",
    "            high_risk_periods = machine_df[machine_df['high_risk']]\n",
    "            plt.scatter(high_risk_periods['Time'], [i + 0.2] * len(high_risk_periods), marker='x', s=100,\n",
    "                        label=f'High Risk Period ({target_alert_type})' if i == 0 else \"\")\n",
    "\n",
    "            plt.text(df['Time'].min(), i, machine_id, va='center', ha='right', fontweight='bold')\n",
    "\n",
    "        plt.yticks(range(n_machines), machines)\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Machine ID')\n",
    "        plt.title(f'Actual Alerts vs High Risk Periods for {target_alert_type} Alerts')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductionAlertPredictor:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the production predictor that handles both XGBoost and Random Forest models.\n",
    "        \"\"\"\n",
    "        self.models = {}\n",
    "        self.scalers = {}\n",
    "        self.alert_types = ['LOW', 'MEDIUM', 'HIGH']\n",
    "        self.features = [\n",
    "            'ChlPrs',\n",
    "            # 'hour',\n",
    "            # 'day_of_week',\n",
    "            # 'month',\n",
    "            # 'is_weekend',\n",
    "            'rolling_mean',\n",
    "            'rolling_std'\n",
    "        ] + [f'time_since_{at}' for at in self.alert_types]\n",
    "\n",
    "    def save_models(self, xgb_predictor: AlertPredictor, rf_predictor: AlertPredictor,\n",
    "                   save_dir: str = 'production_models') -> None:\n",
    "        \"\"\"\n",
    "        Save trained models and scalers to disk.\n",
    "\n",
    "        Args:\n",
    "            xgb_predictor: Trained XGBoost AlertPredictor instance\n",
    "            rf_predictor: Trained Random Forest AlertPredictor instance\n",
    "            save_dir: Directory to save the models\n",
    "        \"\"\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        # Save metadata\n",
    "        metadata = {\n",
    "            'features': self.features,\n",
    "            'alert_types': self.alert_types,\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "        }\n",
    "        joblib.dump(metadata, os.path.join(save_dir, 'metadata.joblib'))\n",
    "\n",
    "        # Save models and scalers\n",
    "        for alert_type in self.alert_types:\n",
    "            # Save XGBoost models and scalers\n",
    "            joblib.dump(\n",
    "                xgb_predictor.models[alert_type],\n",
    "                os.path.join(save_dir, f'xgboost_{alert_type.lower()}_model.joblib')\n",
    "            )\n",
    "            joblib.dump(\n",
    "                xgb_predictor.scalers[alert_type],\n",
    "                os.path.join(save_dir, f'xgboost_{alert_type.lower()}_scaler.joblib')\n",
    "            )\n",
    "\n",
    "            # Save Random Forest models and scalers\n",
    "            joblib.dump(\n",
    "                rf_predictor.models[alert_type],\n",
    "                os.path.join(save_dir, f'randomforest_{alert_type.lower()}_model.joblib')\n",
    "            )\n",
    "            joblib.dump(\n",
    "                rf_predictor.scalers[alert_type],\n",
    "                os.path.join(save_dir, f'randomforest_{alert_type.lower()}_scaler.joblib')\n",
    "            )\n",
    "\n",
    "    def load_models(self, load_dir: str = 'production_models') -> None:\n",
    "        \"\"\"\n",
    "        Load saved models and scalers from disk.\n",
    "\n",
    "        Args:\n",
    "            load_dir: Directory containing the saved models\n",
    "        \"\"\"\n",
    "        # Load metadata\n",
    "        metadata = joblib.load(os.path.join(load_dir, 'metadata.joblib'))\n",
    "        self.features = metadata['features']\n",
    "        self.alert_types = metadata['alert_types']\n",
    "\n",
    "        # Initialize nested dictionaries for models and scalers\n",
    "        self.models = {'xgboost': {}, 'randomforest': {}}\n",
    "        self.scalers = {'xgboost': {}, 'randomforest': {}}\n",
    "\n",
    "        # Load models and scalers\n",
    "        for alert_type in self.alert_types:\n",
    "            # Load XGBoost\n",
    "            self.models['xgboost'][alert_type] = joblib.load(\n",
    "                os.path.join(load_dir, f'xgboost_{alert_type.lower()}_model.joblib')\n",
    "            )\n",
    "            self.scalers['xgboost'][alert_type] = joblib.load(\n",
    "                os.path.join(load_dir, f'xgboost_{alert_type.lower()}_scaler.joblib')\n",
    "            )\n",
    "\n",
    "            # Load Random Forest\n",
    "            self.models['randomforest'][alert_type] = joblib.load(\n",
    "                os.path.join(load_dir, f'randomforest_{alert_type.lower()}_model.joblib')\n",
    "            )\n",
    "            self.scalers['randomforest'][alert_type] = joblib.load(\n",
    "                os.path.join(load_dir, f'randomforest_{alert_type.lower()}_scaler.joblib')\n",
    "            )\n",
    "\n",
    "    def prepare_features(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Prepare features for prediction.\n",
    "\n",
    "        Args:\n",
    "            data: DataFrame containing at minimum 'Time', 'ChlPrs', and 'machine_id' columns\n",
    "\n",
    "        Returns:\n",
    "            DataFrame with engineered features\n",
    "        \"\"\"\n",
    "        df = data.copy()\n",
    "\n",
    "        # Time-based features\n",
    "        df['Time'] = pd.to_datetime(df['Time'])\n",
    "        df['hour'] = df['Time'].dt.hour\n",
    "        df['day_of_week'] = df['Time'].dt.dayofweek\n",
    "        df['month'] = df['Time'].dt.month\n",
    "        df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "        # Rolling statistics\n",
    "        df['rolling_mean'] = df.groupby('machine_id')['ChlPrs'].rolling(\n",
    "            window=24, min_periods=1).mean().reset_index(0, drop=True)\n",
    "        df['rolling_std'] = df.groupby('machine_id')['ChlPrs'].rolling(\n",
    "            window=24, min_periods=1).std().reset_index(0, drop=True)\n",
    "\n",
    "        # Time since last alert features\n",
    "        for alert_type in self.alert_types:\n",
    "            if 'ALERT' in df.columns:\n",
    "                df[f'time_since_{alert_type}'] = df.groupby('machine_id').apply(\n",
    "                    lambda x: x['Time'] - x[x['ALERT'] == alert_type]['Time'].shift(1)\n",
    "                ).reset_index(level=0, drop=True)\n",
    "                df[f'time_since_{alert_type}'] = df[f'time_since_{alert_type}'].dt.total_seconds() / 3600\n",
    "            else:\n",
    "                # For new data without alert history, use a large value\n",
    "                df[f'time_since_{alert_type}'] = 168  # One week in hours\n",
    "\n",
    "        return df[self.features]\n",
    "\n",
    "    def predict(self, data: pd.DataFrame, model_type: str = 'xgboost') -> Dict[str, Dict[str, float]]:\n",
    "        \"\"\"\n",
    "        Make predictions using the loaded models.\n",
    "\n",
    "        Args:\n",
    "            data: DataFrame containing required features\n",
    "            model_type: 'xgboost' or 'randomforest'\n",
    "\n",
    "        Returns:\n",
    "            Dictionary containing predictions for each machine and alert type\n",
    "        \"\"\"\n",
    "        if model_type not in ['xgboost', 'randomforest']:\n",
    "            raise ValueError(\"model_type must be 'xgboost' or 'randomforest'\")\n",
    "\n",
    "        # Prepare features\n",
    "        X = self.prepare_features(data)\n",
    "\n",
    "        # Make predictions for each machine and alert type\n",
    "        predictions = {}\n",
    "        for machine_id in data['machine_id'].unique():\n",
    "            machine_data = X[data['machine_id'] == machine_id]\n",
    "            machine_predictions = {}\n",
    "\n",
    "            for alert_type in self.alert_types:\n",
    "                # Scale the features\n",
    "                X_scaled = self.scalers[model_type][alert_type].transform(machine_data)\n",
    "\n",
    "                # Get prediction probabilities\n",
    "                probs = self.models[model_type][alert_type].predict_proba(X_scaled)[:, 1]\n",
    "\n",
    "                # Store the average probability for this alert type\n",
    "                machine_predictions[alert_type] = float(probs.mean())\n",
    "\n",
    "            predictions[machine_id] = machine_predictions\n",
    "\n",
    "        return predictions\n",
    "\n",
    "def save_trained_models(xgb_predictor: AlertPredictor, rf_predictor: AlertPredictor,\n",
    "                       save_dir: str = 'production_models') -> None:\n",
    "    \"\"\"\n",
    "    Convenience function to save trained models.\n",
    "    \"\"\"\n",
    "    production_predictor = ProductionAlertPredictor()\n",
    "    production_predictor.save_models(xgb_predictor, rf_predictor, save_dir)\n",
    "    print(f\"Models saved successfully to {save_dir}\")\n",
    "\n",
    "def load_production_predictor(load_dir: str = 'production_models') -> ProductionAlertPredictor:\n",
    "    \"\"\"\n",
    "    Convenience function to load saved models.\n",
    "    \"\"\"\n",
    "    production_predictor = ProductionAlertPredictor()\n",
    "    production_predictor.load_models(load_dir)\n",
    "    return production_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d7/0np89js16x9b596pzk8m108c0000gn/T/ipykernel_39763/2447239753.py:45: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f'time_since_{alert_type}'] = df.groupby('machine_id').apply(\n",
      "/var/folders/d7/0np89js16x9b596pzk8m108c0000gn/T/ipykernel_39763/2447239753.py:45: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f'time_since_{alert_type}'] = df.groupby('machine_id').apply(\n",
      "/var/folders/d7/0np89js16x9b596pzk8m108c0000gn/T/ipykernel_39763/2447239753.py:45: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f'time_since_{alert_type}'] = df.groupby('machine_id').apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model for LOW alerts:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d7/0np89js16x9b596pzk8m108c0000gn/T/ipykernel_39763/2447239753.py:55: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df['target'] = df.groupby('machine_id').apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.86      0.93    265420\n",
      "         1.0       0.01      0.84      0.02       521\n",
      "\n",
      "    accuracy                           0.86    265941\n",
      "   macro avg       0.51      0.85      0.48    265941\n",
      "weighted avg       1.00      0.86      0.92    265941\n",
      "\n",
      "\n",
      "Training model for MEDIUM alerts:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d7/0np89js16x9b596pzk8m108c0000gn/T/ipykernel_39763/2447239753.py:55: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df['target'] = df.groupby('machine_id').apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    265918\n",
      "         1.0       0.06      1.00      0.12        23\n",
      "\n",
      "    accuracy                           1.00    265941\n",
      "   macro avg       0.53      1.00      0.56    265941\n",
      "weighted avg       1.00      1.00      1.00    265941\n",
      "\n",
      "\n",
      "Training model for HIGH alerts:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d7/0np89js16x9b596pzk8m108c0000gn/T/ipykernel_39763/2447239753.py:55: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df['target'] = df.groupby('machine_id').apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    265931\n",
      "         1.0       0.00      0.40      0.01        10\n",
      "\n",
      "    accuracy                           1.00    265941\n",
      "   macro avg       0.50      0.70      0.50    265941\n",
      "weighted avg       1.00      1.00      1.00    265941\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d7/0np89js16x9b596pzk8m108c0000gn/T/ipykernel_39763/2447239753.py:45: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f'time_since_{alert_type}'] = df.groupby('machine_id').apply(\n",
      "/var/folders/d7/0np89js16x9b596pzk8m108c0000gn/T/ipykernel_39763/2447239753.py:45: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f'time_since_{alert_type}'] = df.groupby('machine_id').apply(\n",
      "/var/folders/d7/0np89js16x9b596pzk8m108c0000gn/T/ipykernel_39763/2447239753.py:45: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f'time_since_{alert_type}'] = df.groupby('machine_id').apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model for LOW alerts:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d7/0np89js16x9b596pzk8m108c0000gn/T/ipykernel_39763/2447239753.py:55: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df['target'] = df.groupby('machine_id').apply(\n"
     ]
    }
   ],
   "source": [
    "folder = \"../../../outlier_tolerance=5_grouping_time_window=200_anomaly_threshold=6_start_date=2022-01-01_end_date=2026-01-01\"\n",
    "prediction_window = 7  # days\n",
    "\n",
    "# Train models\n",
    "xgb_predictor = AlertPredictor(model_type='xgboost')\n",
    "xgb_predictor.train(folder, prediction_window)\n",
    "\n",
    "rf_predictor = AlertPredictor(model_type='randomforest')\n",
    "rf_predictor.train(folder, prediction_window)\n",
    "\n",
    "# Save the trained models\n",
    "save_trained_models(xgb_predictor, rf_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions for HTOL-09:\n",
      "XGBoost predictions:\n",
      "LOW: 0.887\n",
      "MEDIUM: 0.000\n",
      "HIGH: 0.000\n",
      "\n",
      "Random Forest predictions:\n",
      "LOW: 0.690\n",
      "MEDIUM: 0.310\n",
      "HIGH: 0.320\n"
     ]
    }
   ],
   "source": [
    "# Load the production predictor\n",
    "predictor = load_production_predictor()\n",
    "\n",
    "# Example new data\n",
    "new_data = pd.DataFrame({\n",
    "    'Time': ['2024-11-02 12:00:00'],\n",
    "    'machine_id': ['HTOL-09'],\n",
    "    'ChlPrs': [5]\n",
    "})\n",
    "\n",
    "# Get predictions from both models\n",
    "xgb_predictions = predictor.predict(new_data, model_type='xgboost')\n",
    "rf_predictions = predictor.predict(new_data, model_type='randomforest')\n",
    "\n",
    "# Print predictions\n",
    "for machine_id, predictions in xgb_predictions.items():\n",
    "    print(f\"\\nPredictions for {machine_id}:\")\n",
    "    print(\"XGBoost predictions:\")\n",
    "    for alert_type, prob in predictions.items():\n",
    "        print(f\"{alert_type}: {prob:.3f}\")\n",
    "\n",
    "    print(\"\\nRandom Forest predictions:\")\n",
    "    rf_preds = rf_predictions[machine_id]\n",
    "    for alert_type, prob in rf_preds.items():\n",
    "        print(f\"{alert_type}: {prob:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
